{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ImprovedCreditScoring:\n",
        "    def __init__(self, n_splits=5, random_state=42):\n",
        "        self.n_splits = n_splits\n",
        "        self.random_state = random_state\n",
        "\n",
        "        # Modified base models with better hyperparameters\n",
        "        self.base_models = {\n",
        "            'xgb1': xgb.XGBClassifier(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.03,\n",
        "                max_depth=5,\n",
        "                subsample=0.85,\n",
        "                colsample_bytree=0.8,\n",
        "                min_child_weight=3,\n",
        "                scale_pos_weight=2,  # Handle class imbalance\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'xgb2': xgb.XGBClassifier(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.03,\n",
        "                max_depth=4,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.9,\n",
        "                min_child_weight=4,\n",
        "                scale_pos_weight=2,\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'rf': RandomForestClassifier(\n",
        "                n_estimators=300,\n",
        "                max_depth=6,\n",
        "                min_samples_split=30,\n",
        "                min_samples_leaf=15,\n",
        "                class_weight='balanced',  # Handle class imbalance\n",
        "                random_state=random_state\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # Use L2 regularization in meta model\n",
        "        self.meta_model = LogisticRegression(C=0.8, class_weight='balanced', random_state=random_state)\n",
        "        self.scaler = RobustScaler()  # More robust to outliers\n",
        "\n",
        "    def preprocess_data(self, data):\n",
        "        \"\"\"Enhanced preprocessing with feature engineering\"\"\"\n",
        "        # Handle missing values more sophisticatedly\n",
        "        data = data.copy()\n",
        "\n",
        "        # Separate features by type\n",
        "        onus_cols = [col for col in data.columns if col.startswith('onus_attribute')]\n",
        "        trans_cols = [col for col in data.columns if col.startswith('transaction_attribute')]\n",
        "        bureau_cols = [col for col in data.columns if col.startswith('bureau') and not col.startswith('bureau_enquiry')]\n",
        "        enquiry_cols = [col for col in data.columns if col.startswith('bureau_enquiry')]\n",
        "\n",
        "        # Fill missing values based on feature type\n",
        "        data[onus_cols] = data[onus_cols].fillna(data[onus_cols].median())\n",
        "        data[trans_cols] = data[trans_cols].fillna(0)  # Assume missing transactions are 0\n",
        "        data[bureau_cols] = data[bureau_cols].fillna(data[bureau_cols].median())\n",
        "        data[enquiry_cols] = data[enquiry_cols].fillna(0)  # Assume missing enquiries are 0\n",
        "\n",
        "        # Feature engineering\n",
        "        # Transaction ratios\n",
        "        for col in trans_cols:\n",
        "            if 'value' in col:\n",
        "                corresponding_count = col.replace('value', 'count')\n",
        "                if corresponding_count in trans_cols:\n",
        "                    data[f'{col}_per_transaction'] = data[col] / (data[corresponding_count] + 1)\n",
        "\n",
        "        # Bureau ratios\n",
        "        total_accounts = data[[col for col in bureau_cols if 'count' in col]].sum(axis=1)\n",
        "        for col in bureau_cols:\n",
        "            if 'count' in col:\n",
        "                data[f'{col}_ratio'] = data[col] / (total_accounts + 1)\n",
        "\n",
        "        # Scale features\n",
        "        numerical_cols = onus_cols + trans_cols + bureau_cols + enquiry_cols\n",
        "        data[numerical_cols] = self.scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "        return data\n",
        "\n",
        "    def generate_meta_features(self, X, y=None, is_train=True):\n",
        "        \"\"\"Generate meta-features using stratified k-fold\"\"\"\n",
        "        if is_train:\n",
        "            meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
        "            # Use StratifiedKFold for better handling of imbalanced data\n",
        "            kf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
        "\n",
        "            for i, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
        "                X_train_fold = X.iloc[train_idx]\n",
        "                y_train_fold = y.iloc[train_idx]\n",
        "                X_valid_fold = X.iloc[valid_idx]\n",
        "\n",
        "                for j, (name, model) in enumerate(self.base_models.items()):\n",
        "                    model.fit(X_train_fold, y_train_fold)\n",
        "                    meta_features[valid_idx, j] = model.predict_proba(X_valid_fold)[:, 1]\n",
        "\n",
        "            return meta_features\n",
        "        else:\n",
        "            meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
        "            for j, (name, model) in enumerate(self.base_models.items()):\n",
        "                meta_features[:, j] = model.predict_proba(X)[:, 1]\n",
        "            return meta_features\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Enhanced fitting with feature importance analysis\"\"\"\n",
        "        # Generate meta-features\n",
        "        meta_features = self.generate_meta_features(X, y, is_train=True)\n",
        "\n",
        "        # Fit meta-model\n",
        "        self.meta_model.fit(meta_features, y)\n",
        "\n",
        "        # Store feature importances from XGBoost models\n",
        "        self.feature_importances_ = {}\n",
        "        for name, model in self.base_models.items():\n",
        "            if isinstance(model, xgb.XGBClassifier):\n",
        "                self.feature_importances_[name] = dict(zip(X.columns, model.feature_importances_))\n",
        "\n",
        "        # Retrain base models on full data\n",
        "        for name, model in self.base_models.items():\n",
        "            model.fit(X, y)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Generate probability predictions with optional calibration\"\"\"\n",
        "        meta_features = self.generate_meta_features(X, is_train=False)\n",
        "        return self.meta_model.predict_proba(meta_features)[:, 1]\n",
        "\n",
        "    def get_top_features(self, n=20):\n",
        "        \"\"\"Get top n most important features from XGBoost models\"\"\"\n",
        "        all_importances = {}\n",
        "        for name, importances in self.feature_importances_.items():\n",
        "            for feature, importance in importances.items():\n",
        "                if feature not in all_importances:\n",
        "                    all_importances[feature] = 0\n",
        "                all_importances[feature] += importance\n",
        "\n",
        "        return dict(sorted(all_importances.items(), key=lambda x: x[1], reverse=True)[:n])"
      ],
      "metadata": {
        "id": "qEdw5Kj37el5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, accuracy_score, confusion_matrix, classification_report\n",
        "import warnings\n",
        "import zipfile\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class CreditScorer:\n",
        "    def __init__(self, n_splits=5, random_state=42):\n",
        "        self.n_splits = n_splits\n",
        "        self.random_state = random_state\n",
        "\n",
        "        # Define base models\n",
        "        self.base_models = {\n",
        "            'xgb1': xgb.XGBClassifier(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.03,\n",
        "                max_depth=5,\n",
        "                subsample=0.85,\n",
        "                colsample_bytree=0.8,\n",
        "                min_child_weight=3,\n",
        "                scale_pos_weight=2,\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'xgb2': xgb.XGBClassifier(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.03,\n",
        "                max_depth=4,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.9,\n",
        "                min_child_weight=4,\n",
        "                scale_pos_weight=2,\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'rf': RandomForestClassifier(\n",
        "                n_estimators=300,\n",
        "                max_depth=6,\n",
        "                min_samples_split=30,\n",
        "                min_samples_leaf=15,\n",
        "                class_weight='balanced',\n",
        "                random_state=random_state\n",
        "            )\n",
        "        }\n",
        "        self.meta_model = LogisticRegression(C=0.8, class_weight='balanced', random_state=random_state)\n",
        "\n",
        "    def generate_meta_features(self, X, y=None, is_train=True):\n",
        "        if is_train:\n",
        "            meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
        "            kf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
        "\n",
        "            for i, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
        "                X_train_fold = X.iloc[train_idx]\n",
        "                y_train_fold = y.iloc[train_idx]\n",
        "                X_valid_fold = X.iloc[valid_idx]\n",
        "\n",
        "                for j, (name, model) in enumerate(self.base_models.items()):\n",
        "                    model.fit(X_train_fold, y_train_fold)\n",
        "                    meta_features[valid_idx, j] = model.predict_proba(X_valid_fold)[:, 1]\n",
        "\n",
        "            return meta_features\n",
        "        else:\n",
        "            meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
        "            for j, (name, model) in enumerate(self.base_models.items()):\n",
        "                meta_features[:, j] = model.predict_proba(X)[:, 1]\n",
        "            return meta_features\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        meta_features = self.generate_meta_features(X, y, is_train=True)\n",
        "        self.meta_model.fit(meta_features, y)\n",
        "\n",
        "        # Retrain base models on full data\n",
        "        for name, model in self.base_models.items():\n",
        "            model.fit(X, y)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        meta_features = self.generate_meta_features(X, is_train=False)\n",
        "        return self.meta_model.predict_proba(meta_features)[:, 1]\n",
        "\n",
        "def extract_zip(zip_path, extract_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    extracted_files = [f for f in os.listdir(extract_path) if f.endswith('.csv')]\n",
        "    if not extracted_files:\n",
        "        raise ValueError(\"No CSV file found in the extracted contents\")\n",
        "    return os.path.join(extract_path, extracted_files[0])\n",
        "\n",
        "def print_metrics(metrics):\n",
        "    print(\"\\nModel Performance Metrics:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"AUC Score: {metrics['auc_score']:.4f}\")\n",
        "    print(f\"Average Precision: {metrics['avg_precision']:.4f}\")\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"True Negatives: {metrics['confusion_matrix']['tn']}\")\n",
        "    print(f\"False Positives: {metrics['confusion_matrix']['fp']}\")\n",
        "    print(f\"False Negatives: {metrics['confusion_matrix']['fn']}\")\n",
        "    print(f\"True Positives: {metrics['confusion_matrix']['tp']}\")\n",
        "\n",
        "\n",
        "print(\"Loading development data...\")\n",
        "dev_data = pd.read_csv('/content/cleaned_dev.csv')\n",
        "\n",
        "# Create temporary directory for validation data\n",
        "temp_dir = 'temp_extracted'\n",
        "os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    # Extract and load validation data\n",
        "    print(\"Loading validation data...\")\n",
        "    val_csv_path = extract_zip('/content/validation_data_to_be_shared 3.zip', temp_dir)\n",
        "    val_data = pd.read_csv(val_csv_path)\n",
        "\n",
        "    # Prepare features and target\n",
        "    target = 'bad_flag'\n",
        "    features = [col for col in dev_data.columns if col not in [target, 'account_number']]\n",
        "\n",
        "    print(\"Training model...\")\n",
        "    # Initialize and train model\n",
        "    model = CreditScorer()\n",
        "    model.fit(dev_data[features], dev_data[target])\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    # Generate predictions\n",
        "    val_predictions = model.predict_proba(val_data[features])\n",
        "\n",
        "    # Create submission file\n",
        "    submission = pd.DataFrame({\n",
        "        'account_number': val_data['account_number'],\n",
        "        'predicted_probability': val_predictions\n",
        "    })\n",
        "\n",
        "    print(\"Saving predictions...\")\n",
        "    # Save predictions\n",
        "    submission.to_csv('predictions1.csv', index=False)\n",
        "\n",
        "    print(\"Done! Predictions saved to 'predictions.csv'\")\n",
        "\n",
        "finally:\n",
        "    # Clean up temporary files\n",
        "    import shutil\n",
        "    if os.path.exists(temp_dir):\n",
        "        shutil.rmtree(temp_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp453th_7ggK",
        "outputId": "d7c2fecb-48aa-4efb-ce4f-07f6a86f3608"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading development data...\n",
            "Loading validation data...\n",
            "Training model...\n",
            "Generating predictions...\n",
            "Saving predictions...\n",
            "Done! Predictions saved to 'predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, accuracy_score, confusion_matrix, classification_report\n",
        "import warnings\n",
        "import zipfile\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class CreditScorer:\n",
        "    def __init__(self, n_splits=5, random_state=42):\n",
        "        self.n_splits = n_splits\n",
        "        self.random_state = random_state\n",
        "\n",
        "        # Define base models\n",
        "        self.base_models = {\n",
        "            'xgb1': xgb.XGBClassifier(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.03,\n",
        "                max_depth=5,\n",
        "                subsample=0.85,\n",
        "                colsample_bytree=0.8,\n",
        "                min_child_weight=3,\n",
        "                scale_pos_weight=2,\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'xgb2': xgb.XGBClassifier(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.03,\n",
        "                max_depth=4,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.9,\n",
        "                min_child_weight=4,\n",
        "                scale_pos_weight=2,\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'rf': RandomForestClassifier(\n",
        "                n_estimators=300,\n",
        "                max_depth=6,\n",
        "                min_samples_split=30,\n",
        "                min_samples_leaf=15,\n",
        "                class_weight='balanced',\n",
        "                random_state=random_state\n",
        "            )\n",
        "        }\n",
        "        self.meta_model = LogisticRegression(C=0.8, class_weight='balanced', random_state=random_state)\n",
        "\n",
        "    def generate_meta_features(self, X, y=None, is_train=True):\n",
        "        if is_train:\n",
        "            meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
        "            kf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
        "\n",
        "            # Store CV scores\n",
        "            self.cv_scores = []\n",
        "\n",
        "            for i, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
        "                X_train_fold = X.iloc[train_idx]\n",
        "                y_train_fold = y.iloc[train_idx]\n",
        "                X_valid_fold = X.iloc[valid_idx]\n",
        "                y_valid_fold = y.iloc[valid_idx]\n",
        "\n",
        "                fold_preds = np.zeros(len(valid_idx))\n",
        "                for j, (name, model) in enumerate(self.base_models.items()):\n",
        "                    model.fit(X_train_fold, y_train_fold)\n",
        "                    proba = model.predict_proba(X_valid_fold)[:, 1]\n",
        "                    meta_features[valid_idx, j] = proba\n",
        "                    fold_preds += proba / len(self.base_models)\n",
        "\n",
        "                # Calculate and store fold score\n",
        "                fold_score = roc_auc_score(y_valid_fold, fold_preds)\n",
        "                self.cv_scores.append(fold_score)\n",
        "                print(f\"Fold {i+1} AUC: {fold_score:.4f}\")\n",
        "\n",
        "            print(f\"\\nMean CV AUC: {np.mean(self.cv_scores):.4f} (+/- {np.std(self.cv_scores):.4f})\")\n",
        "            return meta_features\n",
        "        else:\n",
        "            meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
        "            for j, (name, model) in enumerate(self.base_models.items()):\n",
        "                meta_features[:, j] = model.predict_proba(X)[:, 1]\n",
        "            return meta_features\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        print(\"Generating meta-features and CV scores...\")\n",
        "        meta_features = self.generate_meta_features(X, y, is_train=True)\n",
        "        self.meta_model.fit(meta_features, y)\n",
        "\n",
        "        print(\"\\nTraining base models on full data...\")\n",
        "        for name, model in self.base_models.items():\n",
        "            model.fit(X, y)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        meta_features = self.generate_meta_features(X, is_train=False)\n",
        "        return self.meta_model.predict_proba(meta_features)[:, 1]\n",
        "\n",
        "    def evaluate(self, X, y, threshold=0.5):\n",
        "        \"\"\"Evaluate model performance with multiple metrics\"\"\"\n",
        "        y_pred_proba = self.predict_proba(X)\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
        "\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y, y_pred),\n",
        "            'auc_score': roc_auc_score(y, y_pred_proba),\n",
        "            'avg_precision': average_precision_score(y, y_pred_proba),\n",
        "            'confusion_matrix': {\n",
        "                'tn': tn,\n",
        "                'fp': fp,\n",
        "                'fn': fn,\n",
        "                'tp': tp\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(\"\\nModel Performance Metrics:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"AUC Score: {metrics['auc_score']:.4f}\")\n",
        "        print(f\"Average Precision: {metrics['avg_precision']:.4f}\")\n",
        "\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"True Negatives: {tn}\")\n",
        "        print(f\"False Positives: {fp}\")\n",
        "        print(f\"False Negatives: {fn}\")\n",
        "        print(f\"True Positives: {tp}\")\n",
        "\n",
        "        # Calculate and print additional metrics\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        print(\"\\nAdditional Metrics:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "\n",
        "# Load development data\n",
        "print(\"Loading development data...\")\n",
        "dev_data = pd.read_csv('/content/cleaned_dev.csv')\n",
        "\n",
        "# Prepare features and target\n",
        "target = 'bad_flag'\n",
        "features = [col for col in dev_data.columns if col not in [target, 'account_number']]\n",
        "\n",
        "# Split development data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dev_data[features],\n",
        "    dev_data[target],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=dev_data[target]  # Ensure balanced split\n",
        ")\n",
        "\n",
        "print(f\"\\nData split:\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "print(f\"Positive class distribution in train: {(y_train==1).mean():.4f}\")\n",
        "print(f\"Positive class distribution in test: {(y_test==1).mean():.4f}\")\n",
        "\n",
        "# Initialize and train model\n",
        "print(\"\\nTraining model...\")\n",
        "model = CreditScorer()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_metrics = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Create temporary directory for validation data\n",
        "temp_dir = 'temp_extracted'\n",
        "os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    # Extract and load validation data\n",
        "    print(\"\\nLoading validation data...\")\n",
        "    val_csv_path = extract_zip('/content/validation_data_to_be_shared 3.zip', temp_dir)\n",
        "    val_data = pd.read_csv(val_csv_path)\n",
        "\n",
        "    print(\"\\nGenerating predictions for validation data...\")\n",
        "    # Now retrain on full development data before making validation predictions\n",
        "    print(\"\\nRetraining model on full development data...\")\n",
        "    model = CreditScorer()\n",
        "    model.fit(dev_data[features], dev_data[target])\n",
        "\n",
        "    # Generate predictions for validation data\n",
        "    val_predictions = model.predict_proba(val_data[features])\n",
        "\n",
        "    # Create submission file\n",
        "    submission = pd.DataFrame({\n",
        "        'account_number': val_data['account_number'],\n",
        "        'predicted_probability': val_predictions\n",
        "    })\n",
        "\n",
        "    print(\"\\nSaving predictions...\")\n",
        "    submission.to_csv('predictions2.csv', index=False)\n",
        "    print(\"\\nDone! Predictions saved to 'predictions.csv'\")\n",
        "\n",
        "finally:\n",
        "    # Clean up temporary files\n",
        "    import shutil\n",
        "    if os.path.exists(temp_dir):\n",
        "        shutil.rmtree(temp_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDRkAIPHAZLD",
        "outputId": "7db0d05e-8ea8-46d4-fcc3-ce90af214e5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading development data...\n",
            "\n",
            "Data split:\n",
            "Training samples: 2376\n",
            "Testing samples: 595\n",
            "Positive class distribution in train: 0.1431\n",
            "Positive class distribution in test: 0.1429\n",
            "\n",
            "Training model...\n",
            "Generating meta-features and CV scores...\n",
            "Fold 1 AUC: 0.7091\n",
            "Fold 2 AUC: 0.7339\n",
            "Fold 3 AUC: 0.7375\n",
            "Fold 4 AUC: 0.7425\n",
            "Fold 5 AUC: 0.7314\n",
            "\n",
            "Mean CV AUC: 0.7309 (+/- 0.0115)\n",
            "\n",
            "Training base models on full data...\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Model Performance Metrics:\n",
            "==================================================\n",
            "Accuracy: 0.7899\n",
            "AUC Score: 0.9189\n",
            "Average Precision: 0.5699\n",
            "\n",
            "Confusion Matrix:\n",
            "--------------------------------------------------\n",
            "True Negatives: 390\n",
            "False Positives: 120\n",
            "False Negatives: 5\n",
            "True Positives: 80\n",
            "\n",
            "Additional Metrics:\n",
            "--------------------------------------------------\n",
            "Precision: 0.4000\n",
            "Recall: 0.9412\n",
            "F1 Score: 0.5614\n",
            "\n",
            "Loading validation data...\n",
            "\n",
            "Generating predictions for validation data...\n",
            "\n",
            "Retraining model on full development data...\n",
            "Generating meta-features and CV scores...\n",
            "Fold 1 AUC: 0.7370\n",
            "Fold 2 AUC: 0.7145\n",
            "Fold 3 AUC: 0.7337\n",
            "Fold 4 AUC: 0.7189\n",
            "Fold 5 AUC: 0.6902\n",
            "\n",
            "Mean CV AUC: 0.7189 (+/- 0.0167)\n",
            "\n",
            "Training base models on full data...\n",
            "\n",
            "Saving predictions...\n",
            "\n",
            "Done! Predictions saved to 'predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "import warnings\n",
        "import zipfile\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ImprovedCreditScorer:\n",
        "    def __init__(self, n_splits=5, random_state=42):\n",
        "        self.n_splits = n_splits\n",
        "        self.random_state = random_state\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_names_ = None\n",
        "\n",
        "        # Define base models with adjusted parameters\n",
        "        self.base_models = {\n",
        "            'xgb1': xgb.XGBClassifier(\n",
        "                n_estimators=500,\n",
        "                learning_rate=0.02,\n",
        "                max_depth=4,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                min_child_weight=4,\n",
        "                scale_pos_weight=3,  # Increased penalty for false positives\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'xgb2': xgb.XGBClassifier(\n",
        "                n_estimators=500,\n",
        "                learning_rate=0.02,\n",
        "                max_depth=3,\n",
        "                subsample=0.85,\n",
        "                colsample_bytree=0.9,\n",
        "                min_child_weight=5,\n",
        "                scale_pos_weight=3,\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'rf': RandomForestClassifier(\n",
        "                n_estimators=500,\n",
        "                max_depth=5,\n",
        "                min_samples_split=25,\n",
        "                min_samples_leaf=10,\n",
        "                class_weight={0: 1, 1: 3},  # Increased penalty for false positives\n",
        "                random_state=random_state\n",
        "            )\n",
        "        }\n",
        "        self.meta_model = LogisticRegression(C=0.6, class_weight={0: 1, 1: 3}, random_state=random_state)\n",
        "\n",
        "        # Initialize sampling strategy\n",
        "        self.sampler = Pipeline([\n",
        "            ('under', RandomUnderSampler(sampling_strategy=0.5, random_state=random_state)),\n",
        "            ('over', SMOTE(sampling_strategy=0.8, random_state=random_state))\n",
        "        ])\n",
        "\n",
        "    def engineer_features(self, X):\n",
        "        \"\"\"Engineer features from transaction, bureau, and onus attributes\"\"\"\n",
        "        X_new = X.copy()\n",
        "\n",
        "        # Transaction attribute aggregations\n",
        "        tx_cols = [col for col in X.columns if col.startswith('transaction_attribute_')]\n",
        "        if tx_cols:\n",
        "            # Average of non-zero transaction values\n",
        "            X_new['avg_nonzero_tx'] = X[tx_cols].replace(0, np.nan).mean(axis=1)\n",
        "            # Count of non-zero transactions\n",
        "            X_new['nonzero_tx_count'] = (X[tx_cols] != 0).sum(axis=1)\n",
        "            # Transaction value volatility\n",
        "            X_new['tx_volatility'] = X[tx_cols].std(axis=1)\n",
        "\n",
        "        # Bureau data aggregations\n",
        "        bureau_cols = [col for col in X.columns if col.startswith('bureau_')]\n",
        "        if bureau_cols:\n",
        "            # Average bureau scores\n",
        "            X_new['avg_bureau_score'] = X[bureau_cols].mean(axis=1)\n",
        "            # Standard deviation of bureau scores\n",
        "            X_new['bureau_score_spread'] = X[bureau_cols].std(axis=1)\n",
        "            # Count of non-zero bureau entries\n",
        "            X_new['active_bureau_count'] = (X[bureau_cols] != 0).sum(axis=1)\n",
        "\n",
        "        # Onus attribute aggregations\n",
        "        onus_cols = [col for col in X.columns if col.startswith('onus_attribute_')]\n",
        "        if onus_cols:\n",
        "            # Average of onus attributes\n",
        "            X_new['avg_onus_score'] = X[onus_cols].mean(axis=1)\n",
        "            # Volatility in onus attributes\n",
        "            X_new['onus_volatility'] = X[onus_cols].std(axis=1)\n",
        "\n",
        "        # Bureau enquiry features\n",
        "        enquiry_cols = [col for col in X.columns if col.startswith('bureau_enquiry_')]\n",
        "        if enquiry_cols:\n",
        "            # Total number of enquiries\n",
        "            X_new['total_enquiries'] = X[enquiry_cols].sum(axis=1)\n",
        "            # Recent enquiry intensity (assuming more recent enquiries are later in the sequence)\n",
        "            recent_enquiry_cols = enquiry_cols[-10:]  # Last 10 enquiries\n",
        "            X_new['recent_enquiry_intensity'] = X[recent_enquiry_cols].sum(axis=1)\n",
        "\n",
        "        # Interaction features\n",
        "        if 'avg_bureau_score' in X_new.columns and 'total_enquiries' in X_new.columns:\n",
        "            X_new['bureau_enquiry_risk'] = X_new['avg_bureau_score'] / (X_new['total_enquiries'] + 1)\n",
        "\n",
        "        if 'nonzero_tx_count' in X_new.columns and 'active_bureau_count' in X_new.columns:\n",
        "            X_new['activity_ratio'] = X_new['nonzero_tx_count'] / (X_new['active_bureau_count'] + 1)\n",
        "\n",
        "        # Risk indicators\n",
        "        if 'avg_bureau_score' in X_new.columns:\n",
        "            X_new['high_bureau_risk'] = (X_new['avg_bureau_score'] < X_new['avg_bureau_score'].mean()).astype(int)\n",
        "\n",
        "        if 'total_enquiries' in X_new.columns:\n",
        "            X_new['high_enquiry_risk'] = (X_new['total_enquiries'] > X_new['total_enquiries'].mean()).astype(int)\n",
        "\n",
        "        # Drop any features that ended up with NaN values\n",
        "        X_new = X_new.fillna(0)\n",
        "        self.feature_names_ = list(X_new.columns)\n",
        "\n",
        "        return X_new\n",
        "\n",
        "    def find_optimal_threshold(self, y_true, y_pred_proba):\n",
        "        \"\"\"Find optimal classification threshold based on precision-recall curve\"\"\"\n",
        "        precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred_proba)\n",
        "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "        optimal_threshold = thresholds[np.argmax(f1_scores[:-1])]\n",
        "        return optimal_threshold\n",
        "\n",
        "    def generate_meta_features(self, X, y=None, is_train=True):\n",
        "        if is_train:\n",
        "            meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
        "            kf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
        "\n",
        "            self.cv_scores = []\n",
        "            self.feature_importances_ = {}\n",
        "\n",
        "            for i, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
        "                X_train_fold = X.iloc[train_idx]\n",
        "                y_train_fold = y.iloc[train_idx]\n",
        "                X_valid_fold = X.iloc[valid_idx]\n",
        "                y_valid_fold = y.iloc[valid_idx]\n",
        "\n",
        "                # Apply sampling only to training fold\n",
        "                X_train_resampled, y_train_resampled = self.sampler.fit_resample(X_train_fold, y_train_fold)\n",
        "\n",
        "                fold_preds = np.zeros(len(valid_idx))\n",
        "                for j, (name, model) in enumerate(self.base_models.items()):\n",
        "                    model.fit(X_train_resampled, y_train_resampled)\n",
        "                    proba = model.predict_proba(X_valid_fold)[:, 1]\n",
        "                    meta_features[valid_idx, j] = proba\n",
        "                    fold_preds += proba / len(self.base_models)\n",
        "\n",
        "                    # Store feature importances for tree-based models\n",
        "                    if hasattr(model, 'feature_importances_'):\n",
        "                        if name not in self.feature_importances_:\n",
        "                            self.feature_importances_[name] = np.zeros(X.shape[1])\n",
        "                        self.feature_importances_[name] += model.feature_importances_ / self.n_splits\n",
        "\n",
        "                fold_score = roc_auc_score(y_valid_fold, fold_preds)\n",
        "                self.cv_scores.append(fold_score)\n",
        "                print(f\"Fold {i+1} AUC: {fold_score:.4f}\")\n",
        "\n",
        "            print(f\"\\nMean CV AUC: {np.mean(self.cv_scores):.4f} (+/- {np.std(self.cv_scores):.4f})\")\n",
        "            return meta_features\n",
        "        else:\n",
        "            meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
        "            for j, (name, model) in enumerate(self.base_models.items()):\n",
        "                meta_features[:, j] = model.predict_proba(X)[:, 1]\n",
        "            return meta_features\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        print(\"Engineering features...\")\n",
        "        X_engineered = self.engineer_features(X)\n",
        "\n",
        "        print(\"Scaling features...\")\n",
        "        X_scaled = pd.DataFrame(\n",
        "            self.scaler.fit_transform(X_engineered),\n",
        "            columns=self.feature_names_,\n",
        "            index=X_engineered.index\n",
        "        )\n",
        "\n",
        "        print(\"Generating meta-features and CV scores...\")\n",
        "        meta_features = self.generate_meta_features(X_scaled, y, is_train=True)\n",
        "\n",
        "        self.training_features_ = self.feature_names_\n",
        "\n",
        "        # Resample data for meta-model\n",
        "        meta_features_resampled, y_resampled = self.sampler.fit_resample(meta_features, y)\n",
        "        self.meta_model.fit(meta_features_resampled, y_resampled)\n",
        "\n",
        "        print(\"\\nTraining base models on full data...\")\n",
        "        X_full_resampled, y_full_resampled = self.sampler.fit_resample(X_scaled, y)\n",
        "        for name, model in self.base_models.items():\n",
        "            model.fit(X_full_resampled, y_full_resampled)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X_engineered = self.engineer_features(X)\n",
        "\n",
        "        # Ensure features match training order\n",
        "        X_engineered = X_engineered[self.training_features_]\n",
        "\n",
        "        X_scaled = pd.DataFrame(\n",
        "            self.scaler.transform(X_engineered),\n",
        "            columns=self.training_features_,\n",
        "            index=X_engineered.index\n",
        "        )\n",
        "        meta_features = self.generate_meta_features(X_scaled, is_train=False)\n",
        "        return self.meta_model.predict_proba(meta_features)[:, 1]\n",
        "\n",
        "    def evaluate(self, X, y, threshold=None):\n",
        "        \"\"\"Evalaluate model performance with multiple metrics and optimal threshold\"\"\"\n",
        "        # Ensure features match training features\n",
        "        X_engineered = self.engineer_features(X)\n",
        "        X_eval = X_engineered[self.training_features_]\n",
        "\n",
        "        # Generate predictions\n",
        "        y_pred_proba = self.predict_proba(X_eval)\n",
        "\n",
        "        # Find optimal threshold if not provided\n",
        "        if threshold is None:\n",
        "            threshold = self.find_optimal_threshold(y, y_pred_proba)\n",
        "\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
        "\n",
        "        metrics = {\n",
        "            'threshold': threshold,\n",
        "            'accuracy': accuracy_score(y, y_pred),\n",
        "            'auc_score': roc_auc_score(y, y_pred_proba),\n",
        "            'avg_precision': average_precision_score(y, y_pred_proba),\n",
        "            'confusion_matrix': {\n",
        "                'tn': tn,\n",
        "                'fp': fp,\n",
        "                'fn': fn,\n",
        "                'tp': tp\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(\"\\nModel Performance Metrics:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Optimal Threshold: {threshold:.4f}\")\n",
        "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"AUC Score: {metrics['auc_score']:.4f}\")\n",
        "        print(f\"Average Precision: {metrics['avg_precision']:.4f}\")\n",
        "\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"True Negatives: {tn}\")\n",
        "        print(f\"False Positives: {fp}\")\n",
        "        print(f\"False Negatives: {fn}\")\n",
        "        print(f\"True Positives: {tp}\")\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        print(\"\\nAdditional Metrics:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "        if hasattr(self, 'feature_importances_'):\n",
        "            print(\"\\nTop 10 Important Features:\")\n",
        "            print(\"-\" * 50)\n",
        "            for name, importances in self.feature_importances_.items():\n",
        "                feat_imp = pd.Series(importances, index=self.training_features_)\n",
        "                print(f\"\\n{name}:\")\n",
        "                print(feat_imp.nlargest(10).to_string())\n",
        "\n",
        "        return metrics\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load development data\n",
        "    print(\"Loading development data...\")\n",
        "    dev_data = pd.read_csv('/content/cleaned_dev.csv')\n",
        "\n",
        "    # Prepare features and target\n",
        "    target = 'bad_flag'\n",
        "    features = [col for col in dev_data.columns if col not in [target, 'account_number']]\n",
        "\n",
        "    # Split development data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        dev_data[features],\n",
        "        dev_data[target],\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=dev_data[target]\n",
        "    )\n",
        "\n",
        "    print(f\"\\nData split:\")\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Testing samples: {len(X_test)}\")\n",
        "    print(f\"Positive class distribution in train: {(y_train==1).mean():.4f}\")\n",
        "    print(f\"Positive class distribution in test: {(y_test==1).mean():.4f}\")\n",
        "\n",
        "    # Initialize and train model\n",
        "    print(\"\\nTraining model...\")\n",
        "    model = ImprovedCreditScorer()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\nEvaluating on test set...\")\n",
        "    test_metrics = model.evaluate(X_test, y_test)\n",
        "\n",
        "    # Create temporary directory for validation data\n",
        "    temp_dir = 'temp_extracted'\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        # Extract and load validation data\n",
        "        print(\"\\nLoading validation data...\")\n",
        "        with zipfile.ZipFile('/content/validation_data_to_be_shared 3.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall(temp_dir)\n",
        "            val_csv_csv_path = os.path.join(temp_dir, zip_ref.namelist()[0])\n",
        "\n",
        "        val_data = pd.read_csv(val_csv_path)\n",
        "\n",
        "        print(\"\\nGenerating predictions for validation data...\")\n",
        "        # Retrain on full development data before making validation predictions\n",
        "        print(\"\\nRetraining model on full development data...\")\n",
        "        model = ImprovedCreditScorer()\n",
        "        model.fit(dev_data[features], dev_data[target])\n",
        "\n",
        "        # Generate predictions for validation data\n",
        "        val_predictions = model.predict_proba(val_data[features])\n",
        "\n",
        "        # Create submission file\n",
        "        submission = pd.DataFrame({\n",
        "            'account_number': val_data['account_number'],\n",
        "            'predicted_probability': val_predictions\n",
        "        })\n",
        "\n",
        "        print(\"\\nSaving predictions...\")\n",
        "        submission.to_csv('predictions_improved.csv', index=False)\n",
        "        print(\"\\nDone! Predictions saved to 'predictions_improved.csv'\")\n",
        "\n",
        "    finally:\n",
        "        # Clean up temporary files\n",
        "        import shutil\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z-vw7KuFK1L",
        "outputId": "fa0fc6c7-a26e-4715-d412-2f4f6aebaffd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading development data...\n",
            "\n",
            "Data split:\n",
            "Training samples: 2376\n",
            "Testing samples: 595\n",
            "Positive class distribution in train: 0.1431\n",
            "Positive class distribution in test: 0.1429\n",
            "\n",
            "Training model...\n",
            "Engineering features...\n",
            "Scaling features...\n",
            "Generating meta-features and CV scores...\n",
            "Fold 1 AUC: 0.7471\n",
            "Fold 2 AUC: 0.7431\n",
            "Fold 3 AUC: 0.7970\n",
            "Fold 4 AUC: 0.7700\n",
            "Fold 5 AUC: 0.7814\n",
            "\n",
            "Mean CV AUC: 0.7677 (+/- 0.0204)\n",
            "\n",
            "Training base models on full data...\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Model Performance Metrics:\n",
            "==================================================\n",
            "Optimal Threshold: 0.8854\n",
            "Accuracy: 0.8689\n",
            "AUC Score: 0.8699\n",
            "Average Precision: 0.5258\n",
            "\n",
            "Confusion Matrix:\n",
            "--------------------------------------------------\n",
            "True Negatives: 476\n",
            "False Positives: 34\n",
            "False Negatives: 44\n",
            "True Positives: 41\n",
            "\n",
            "Additional Metrics:\n",
            "--------------------------------------------------\n",
            "Precision: 0.5467\n",
            "Recall: 0.4824\n",
            "F1 Score: 0.5125\n",
            "\n",
            "Top 10 Important Features:\n",
            "--------------------------------------------------\n",
            "\n",
            "xgb1:\n",
            "transaction_attribute_151    0.066835\n",
            "bureau_12                    0.049252\n",
            "bureau_398                   0.029334\n",
            "bureau_429                   0.027677\n",
            "bureau_137                   0.023406\n",
            "bureau_126                   0.009483\n",
            "bureau_enquiry_risk          0.009014\n",
            "avg_bureau_score             0.008445\n",
            "transaction_attribute_387    0.007249\n",
            "transaction_attribute_31     0.007149\n",
            "\n",
            "xgb2:\n",
            "transaction_attribute_151    0.075890\n",
            "bureau_12                    0.038736\n",
            "bureau_429                   0.033815\n",
            "bureau_398                   0.030816\n",
            "bureau_137                   0.024526\n",
            "avg_bureau_score             0.010224\n",
            "bureau_enquiry_risk          0.009741\n",
            "transaction_attribute_31     0.009432\n",
            "transaction_attribute_22     0.007346\n",
            "bureau_9                     0.007330\n",
            "\n",
            "rf:\n",
            "bureau_126                   0.032538\n",
            "bureau_429                   0.032513\n",
            "bureau_137                   0.030913\n",
            "bureau_398                   0.027987\n",
            "transaction_attribute_151    0.027767\n",
            "bureau_127                   0.026327\n",
            "bureau_397                   0.026039\n",
            "bureau_34                    0.022870\n",
            "bureau_score_spread          0.022585\n",
            "bureau_419                   0.020112\n",
            "\n",
            "Loading validation data...\n",
            "\n",
            "Generating predictions for validation data...\n",
            "\n",
            "Retraining model on full development data...\n",
            "Engineering features...\n",
            "Scaling features...\n",
            "Generating meta-features and CV scores...\n",
            "Fold 1 AUC: 0.7739\n",
            "Fold 2 AUC: 0.7407\n",
            "Fold 3 AUC: 0.7665\n",
            "Fold 4 AUC: 0.7625\n",
            "Fold 5 AUC: 0.7328\n",
            "\n",
            "Mean CV AUC: 0.7553 (+/- 0.0158)\n",
            "\n",
            "Training base models on full data...\n",
            "\n",
            "Saving predictions...\n",
            "\n",
            "Done! Predictions saved to 'predictions_improved.csv'\n"
          ]
        }
      ]
    }
  ]
}