{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjeqdTU0EiD9LiTbqzBc5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghana-0211/Credit-Card-Behaviour/blob/main/ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9wHgNMMXcoeV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import clone\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "import zipfile\n",
        "import os\n",
        "import tempfile\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def extract_zip(zip_path, extract_dir=None):\n",
        "    \"\"\"\n",
        "    Extract a ZIP file and return the path to the CSV file inside.\n",
        "\n",
        "    Parameters:\n",
        "    zip_path (str): Path to the ZIP file\n",
        "    extract_dir (str): Directory to extract files to. If None, uses a temporary directory\n",
        "\n",
        "    Returns:\n",
        "    str: Path to the extracted CSV file\n",
        "    \"\"\"\n",
        "    if extract_dir is None:\n",
        "        extract_dir = tempfile.mkdtemp()\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "\n",
        "        # Find the CSV file in the extracted contents\n",
        "        csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]\n",
        "        if not csv_files:\n",
        "            raise ValueError(\"No CSV file found in the ZIP archive\")\n",
        "\n",
        "        return os.path.join(extract_dir, csv_files[0])\n",
        "\n",
        "class BalancedEnsembleCreditScorer:\n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_names_ = None\n",
        "        self.training_features_ = None\n",
        "\n",
        "        # Define base models with provided parameters\n",
        "        self.base_models = {\n",
        "            'xgb1': xgb.XGBClassifier(\n",
        "                n_estimators=500, learning_rate=0.02, max_depth=4,\n",
        "                subsample=0.8, colsample_bytree=0.8, min_child_weight=4,\n",
        "                scale_pos_weight=3, random_state=random_state\n",
        "            ),\n",
        "            'xgb2': xgb.XGBClassifier(\n",
        "                n_estimators=500, learning_rate=0.03, max_depth=5,\n",
        "                subsample=0.85, colsample_bytree=0.9, min_child_weight=6,\n",
        "                scale_pos_weight=3, random_state=random_state\n",
        "            ),\n",
        "            'xgb3': xgb.XGBClassifier(\n",
        "                n_estimators=500, learning_rate=0.05, max_depth=3,\n",
        "                subsample=0.9, colsample_bytree=0.75, min_child_weight=3,\n",
        "                scale_pos_weight=3, random_state=random_state\n",
        "            ),\n",
        "            'rf1': RandomForestClassifier(\n",
        "                n_estimators=500, max_depth=5, min_samples_split=25,\n",
        "                min_samples_leaf=10, class_weight={0: 1, 1: 3},\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'rf2': RandomForestClassifier(\n",
        "                n_estimators=500, max_depth=6, min_samples_split=20,\n",
        "                min_samples_leaf=8, class_weight={0: 1, 1: 3},\n",
        "                random_state=random_state\n",
        "            ),\n",
        "            'rf3': RandomForestClassifier(\n",
        "                n_estimators=500, max_depth=4, min_samples_split=30,\n",
        "                min_samples_leaf=12, class_weight={0: 1, 1: 3},\n",
        "                random_state=random_state\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # Initialize meta-model\n",
        "        self.meta_model = LogisticRegression(\n",
        "            C=0.8,\n",
        "            class_weight='balanced',\n",
        "            random_state=random_state,\n",
        "            max_iter=1000\n",
        "        )\n",
        "\n",
        "        # Initialize containers for trained models\n",
        "        self.trained_models = {i: {} for i in range(1, 7)}  # One dict per balanced dataset\n",
        "\n",
        "    def engineer_features(self, X):\n",
        "        \"\"\"Engineer features from transaction, bureau, and onus attributes\"\"\"\n",
        "        X_new = X.copy()\n",
        "\n",
        "        # Transaction attribute aggregations\n",
        "        tx_cols = [col for col in X.columns if col.startswith('transaction_attribute_')]\n",
        "        if tx_cols:\n",
        "            X_new['avg_nonzero_tx'] = X[tx_cols].replace(0, np.nan).mean(axis=1)\n",
        "            X_new['nonzero_tx_count'] = (X[tx_cols] != 0).sum(axis=1)\n",
        "            X_new['tx_volatility'] = X[tx_cols].std(axis=1)\n",
        "\n",
        "        # Bureau data aggregations\n",
        "        bureau_cols = [col for col in X.columns if col.startswith('bureau_')]\n",
        "        if bureau_cols:\n",
        "            X_new['avg_bureau_score'] = X[bureau_cols].mean(axis=1)\n",
        "            X_new['bureau_score_spread'] = X[bureau_cols].std(axis=1)\n",
        "            X_new['active_bureau_count'] = (X[bureau_cols] != 0).sum(axis=1)\n",
        "\n",
        "        # Onus attribute aggregations\n",
        "        onus_cols = [col for col in X.columns if col.startswith('onus_attribute_')]\n",
        "        if onus_cols:\n",
        "            X_new['avg_onus_score'] = X[onus_cols].mean(axis=1)\n",
        "            X_new['onus_volatility'] = X[onus_cols].std(axis=1)\n",
        "\n",
        "        # Bureau enquiry features\n",
        "        enquiry_cols = [col for col in X.columns if col.startswith('bureau_enquiry_')]\n",
        "        if enquiry_cols:\n",
        "            X_new['total_enquiries'] = X[enquiry_cols].sum(axis=1)\n",
        "            recent_enquiry_cols = enquiry_cols[-10:]\n",
        "            X_new['recent_enquiry_intensity'] = X[recent_enquiry_cols].sum(axis=1)\n",
        "\n",
        "        # Interaction features\n",
        "        if 'avg_bureau_score' in X_new.columns and 'total_enquiries' in X_new.columns:\n",
        "            X_new['bureau_enquiry_risk'] = X_new['avg_bureau_score'] / (X_new['total_enquiries'] + 1)\n",
        "\n",
        "        # Fill NaN values and store feature names\n",
        "        X_new = X_new.fillna(0)\n",
        "        self.feature_names_ = list(X_new.columns)\n",
        "\n",
        "        return X_new\n",
        "\n",
        "    def _get_base_predictions(self, X_scaled):\n",
        "        \"\"\"Get predictions from all base models\"\"\"\n",
        "        predictions = np.zeros((X_scaled.shape[0], len(self.trained_models) * len(self.base_models)))\n",
        "        col_idx = 0\n",
        "\n",
        "        for dataset_idx in self.trained_models:\n",
        "            for model_name, model in self.trained_models[dataset_idx].items():\n",
        "                predictions[:, col_idx] = model.predict_proba(X_scaled)[:, 1]\n",
        "                col_idx += 1\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def fit(self, balanced_datasets):\n",
        "        \"\"\"\n",
        "        Fit models on multiple balanced datasets and train meta-model\n",
        "\n",
        "        Parameters:\n",
        "        balanced_datasets: dict of pandas DataFrames, keys should be 1-6\n",
        "        \"\"\"\n",
        "        print(\"Training base models on balanced datasets...\")\n",
        "\n",
        "        # Store feature names from first dataset\n",
        "        X_first = balanced_datasets[1].drop(['bad_flag', 'account_number'], axis=1)\n",
        "        X_engineered = self.engineer_features(X_first)\n",
        "        self.training_features_ = self.feature_names_\n",
        "\n",
        "        # Initialize array to store meta-features\n",
        "        meta_features = []\n",
        "        meta_labels = []\n",
        "\n",
        "        # Train models on each balanced dataset\n",
        "        for dataset_idx, df in balanced_datasets.items():\n",
        "            print(f\"\\nTraining models on balanced dataset {dataset_idx}\")\n",
        "\n",
        "            # Prepare features\n",
        "            X = df.drop(['bad_flag', 'account_number'], axis=1)\n",
        "            y = df['bad_flag']\n",
        "\n",
        "            # Engineer and scale features\n",
        "            X_engineered = self.engineer_features(X)\n",
        "            X_scaled = pd.DataFrame(\n",
        "                self.scaler.fit_transform(X_engineered),\n",
        "                columns=self.feature_names_,\n",
        "                index=X_engineered.index\n",
        "            )\n",
        "\n",
        "            # Train each base model\n",
        "            for model_name, model in self.base_models.items():\n",
        "                print(f\"Training {model_name} on dataset {dataset_idx}...\")\n",
        "                model_clone = clone(model)\n",
        "                model_clone.fit(X_scaled, y)\n",
        "                self.trained_models[dataset_idx][model_name] = model_clone\n",
        "\n",
        "            # Get predictions for meta-model training\n",
        "            dataset_predictions = self._get_base_predictions(X_scaled)\n",
        "            meta_features.append(dataset_predictions)\n",
        "            meta_labels.append(y)\n",
        "\n",
        "        # Combine all meta-features and train meta-model\n",
        "        print(\"\\nTraining meta-model...\")\n",
        "        X_meta = np.vstack(meta_features)\n",
        "        y_meta = np.concatenate(meta_labels)\n",
        "        self.meta_model.fit(X_meta, y_meta)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Generate predictions using meta-model combination of base models\"\"\"\n",
        "        # Engineer features\n",
        "        X_engineered = self.engineer_features(X)\n",
        "        X_engineered = X_engineered[self.training_features_]\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = pd.DataFrame(\n",
        "            self.scaler.transform(X_engineered),\n",
        "            columns=self.training_features_,\n",
        "            index=X_engineered.index\n",
        "        )\n",
        "\n",
        "        # Get base model predictions\n",
        "        base_predictions = self._get_base_predictions(X_scaled)\n",
        "\n",
        "        # Generate final predictions using meta-model\n",
        "        final_predictions = self.meta_model.predict_proba(base_predictions)[:, 1]\n",
        "\n",
        "        return final_predictions\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        \"\"\"Evaluate model performance with multiple metrics\"\"\"\n",
        "        # Generate predictions\n",
        "        y_pred_proba = self.predict_proba(X)\n",
        "\n",
        "        # Find optimal threshold using precision-recall curve\n",
        "        precisions, recalls, thresholds = precision_recall_curve(y, y_pred_proba)\n",
        "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "        optimal_threshold = thresholds[np.argmax(f1_scores[:-1])]\n",
        "\n",
        "        # Generate binary predictions using optimal threshold\n",
        "        y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "        # Calculate metrics\n",
        "        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
        "\n",
        "        metrics = {\n",
        "            'threshold': optimal_threshold,\n",
        "            'accuracy': accuracy_score(y, y_pred),\n",
        "            'auc_score': roc_auc_score(y, y_pred_proba),\n",
        "            'avg_precision': average_precision_score(y, y_pred_proba),\n",
        "            'confusion_matrix': {\n",
        "                'tn': tn, 'fp': fp,\n",
        "                'fn': fn, 'tp': tp\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Print detailed metrics\n",
        "        print(\"\\nModel Performance Metrics:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
        "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"AUC Score: {metrics['auc_score']:.4f}\")\n",
        "        print(f\"Average Precision: {metrics['avg_precision']:.4f}\")\n",
        "\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"True Negatives: {tn}\")\n",
        "        print(f\"False Positives: {fp}\")\n",
        "        print(f\"False Negatives: {fn}\")\n",
        "        print(f\"True Positives: {tp}\")\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        print(\"\\nAdditional Metrics:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and split balanced datasets\n",
        "    balanced_datasets_train = {}\n",
        "    balanced_datasets_test = {}\n",
        "\n",
        "    print(\"Loading and splitting datasets...\")\n",
        "    for i in range(1, 7):\n",
        "        # Load dataset\n",
        "        df = pd.read_excel('/content/balanced_datasets (1).xlsx', sheet_name=f'df_{i}')\n",
        "\n",
        "        # Split the data\n",
        "        train_df, test_df = train_test_split(\n",
        "            df, test_size=0.2, random_state=42,\n",
        "            stratify=df['bad_flag']\n",
        "        )\n",
        "\n",
        "        balanced_datasets_train[i] = train_df\n",
        "        balanced_datasets_test[i] = test_df\n",
        "\n",
        "    # Initialize and train model\n",
        "    print(\"\\nTraining model...\")\n",
        "    model = BalancedEnsembleCreditScorer()\n",
        "    model.fit(balanced_datasets_train)\n",
        "\n",
        "    # Combine all test sets and remove duplicates\n",
        "    print(\"\\nPreparing test data...\")\n",
        "    all_test_data = pd.concat([df for df in balanced_datasets_test.values()], axis=0)\n",
        "    all_test_data = all_test_data.drop_duplicates(subset='account_number')\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"\\nEvaluating model on test set...\")\n",
        "    X_test = all_test_data.drop(['bad_flag', 'account_number'], axis=1)\n",
        "    y_test = all_test_data['bad_flag']\n",
        "\n",
        "    # Get evaluation metrics\n",
        "    metrics = model.evaluate(X_test, y_test)\n",
        "\n",
        "    # Generate and save predictions\n",
        "    predictions = pd.DataFrame({\n",
        "        'account_number': all_test_data['account_number'],\n",
        "        'actual': y_test,\n",
        "        'predicted_probability': model.predict_proba(X_test)\n",
        "    })\n",
        "    predictions.to_csv('predictions_balanced_ensemble101.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vgREOKLg_9Z",
        "outputId": "cd234856-bc5b-4947-969b-8d3b41b6d93c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and splitting datasets...\n",
            "\n",
            "Training model...\n",
            "Training base models on balanced datasets...\n",
            "\n",
            "Training models on balanced dataset 1\n",
            "Training xgb1 on dataset 1...\n",
            "Training xgb2 on dataset 1...\n",
            "Training xgb3 on dataset 1...\n",
            "Training rf1 on dataset 1...\n",
            "Training rf2 on dataset 1...\n",
            "Training rf3 on dataset 1...\n",
            "\n",
            "Training models on balanced dataset 2\n",
            "Training xgb1 on dataset 2...\n",
            "Training xgb2 on dataset 2...\n",
            "Training xgb3 on dataset 2...\n",
            "Training rf1 on dataset 2...\n",
            "Training rf2 on dataset 2...\n",
            "Training rf3 on dataset 2...\n",
            "\n",
            "Training models on balanced dataset 3\n",
            "Training xgb1 on dataset 3...\n",
            "Training xgb2 on dataset 3...\n",
            "Training xgb3 on dataset 3...\n",
            "Training rf1 on dataset 3...\n",
            "Training rf2 on dataset 3...\n",
            "Training rf3 on dataset 3...\n",
            "\n",
            "Training models on balanced dataset 4\n",
            "Training xgb1 on dataset 4...\n",
            "Training xgb2 on dataset 4...\n",
            "Training xgb3 on dataset 4...\n",
            "Training rf1 on dataset 4...\n",
            "Training rf2 on dataset 4...\n",
            "Training rf3 on dataset 4...\n",
            "\n",
            "Training models on balanced dataset 5\n",
            "Training xgb1 on dataset 5...\n",
            "Training xgb2 on dataset 5...\n",
            "Training xgb3 on dataset 5...\n",
            "Training rf1 on dataset 5...\n",
            "Training rf2 on dataset 5...\n",
            "Training rf3 on dataset 5...\n",
            "\n",
            "Training models on balanced dataset 6\n",
            "Training xgb1 on dataset 6...\n",
            "Training xgb2 on dataset 6...\n",
            "Training xgb3 on dataset 6...\n",
            "Training rf1 on dataset 6...\n",
            "Training rf2 on dataset 6...\n",
            "Training rf3 on dataset 6...\n",
            "\n",
            "Training meta-model...\n",
            "\n",
            "Preparing test data...\n",
            "\n",
            "Evaluating model on test set...\n",
            "\n",
            "Model Performance Metrics:\n",
            "==================================================\n",
            "Optimal Threshold: 0.0636\n",
            "Accuracy: 0.9334\n",
            "AUC Score: 0.9320\n",
            "Average Precision: 0.4402\n",
            "\n",
            "Confusion Matrix:\n",
            "--------------------------------------------------\n",
            "True Negatives: 750\n",
            "False Positives: 61\n",
            "False Negatives: 0\n",
            "True Positives: 105\n",
            "\n",
            "Additional Metrics:\n",
            "--------------------------------------------------\n",
            "Precision: 0.6325\n",
            "Recall: 1.0000\n",
            "F1 Score: 0.7749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create temporary directory for zip extraction\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "    # Load and split balanced datasets\n",
        "    balanced_datasets_train = {}\n",
        "    balanced_datasets_test = {}\n",
        "\n",
        "    print(\"Loading and splitting datasets...\")\n",
        "    for i in range(1, 7):\n",
        "        # Load dataset\n",
        "        df = pd.read_excel('/content/balanced_datasets (1).xlsx', sheet_name=f'df_{i}')\n",
        "\n",
        "        # Split the data\n",
        "        train_df, test_df = train_test_split(\n",
        "            df, test_size=0.2, random_state=42,\n",
        "            stratify=df['bad_flag']\n",
        "        )\n",
        "\n",
        "        balanced_datasets_train[i] = train_df\n",
        "        balanced_datasets_test[i] = test_df\n",
        "\n",
        "    # Initialize and train model\n",
        "    print(\"\\nTraining model...\")\n",
        "    model = BalancedEnsembleCreditScorer()\n",
        "    model.fit(balanced_datasets_train)\n",
        "\n",
        "    # Combine all test sets and remove duplicates\n",
        "    print(\"\\nPreparing test data...\")\n",
        "    all_test_data = pd.concat([df for df in balanced_datasets_test.values()], axis=0)\n",
        "    all_test_data = all_test_data.drop_duplicates(subset='account_number')\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"\\nEvaluating model on test set...\")\n",
        "    X_test = all_test_data.drop(['bad_flag', 'account_number'], axis=1)\n",
        "    y_test = all_test_data['bad_flag']\n",
        "\n",
        "    # Get evaluation metrics\n",
        "    metrics = model.evaluate(X_test, y_test)\n",
        "\n",
        "    # Generate and save predictions for test set\n",
        "    predictions = pd.DataFrame({\n",
        "        'account_number': all_test_data['account_number'],\n",
        "        'actual': y_test,\n",
        "        'predicted_probability': model.predict_proba(X_test)\n",
        "    })\n",
        "    predictions.to_csv('predictions_balanced_ensemble101.csv', index=False)\n",
        "\n",
        "    # Load and process validation data\n",
        "    print(\"\\nProcessing validation data...\")\n",
        "    val_csv_path = extract_zip('/content/validation_data_to_be_shared 3.zip', temp_dir)\n",
        "    val_data = pd.read_csv(val_csv_path)\n",
        "\n",
        "    # Generate predictions for validation data\n",
        "    print(\"Generating predictions for validation data...\")\n",
        "    val_predictions = model.predict_proba(val_data.drop(['account_number'], axis=1))\n",
        "\n",
        "    # Create submission file\n",
        "    submission = pd.DataFrame({\n",
        "        'account_number': val_data['account_number'],\n",
        "        'predicted_probability': val_predictions\n",
        "    })\n",
        "\n",
        "    # Save validation predictions\n",
        "    print(\"Saving validation predictions...\")\n",
        "    submission.to_csv('validation_predictions.csv', index=False)\n",
        "\n",
        "    print(\"\\nCompleted! Files saved:\")\n",
        "    print(\"1. predictions_balanced_ensemble101.csv - Test set predictions\")\n",
        "    print(\"2. validation_predictions.csv - Validation set predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stbTWl5K5Ala",
        "outputId": "eb861f68-f9ed-4197-d4bf-c900049d9928"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and splitting datasets...\n",
            "\n",
            "Training model...\n",
            "Training base models on balanced datasets...\n",
            "\n",
            "Training models on balanced dataset 1\n",
            "Training xgb1 on dataset 1...\n",
            "Training xgb2 on dataset 1...\n",
            "Training xgb3 on dataset 1...\n",
            "Training rf1 on dataset 1...\n",
            "Training rf2 on dataset 1...\n",
            "Training rf3 on dataset 1...\n",
            "\n",
            "Training models on balanced dataset 2\n",
            "Training xgb1 on dataset 2...\n",
            "Training xgb2 on dataset 2...\n",
            "Training xgb3 on dataset 2...\n",
            "Training rf1 on dataset 2...\n",
            "Training rf2 on dataset 2...\n",
            "Training rf3 on dataset 2...\n",
            "\n",
            "Training models on balanced dataset 3\n",
            "Training xgb1 on dataset 3...\n",
            "Training xgb2 on dataset 3...\n",
            "Training xgb3 on dataset 3...\n",
            "Training rf1 on dataset 3...\n",
            "Training rf2 on dataset 3...\n",
            "Training rf3 on dataset 3...\n",
            "\n",
            "Training models on balanced dataset 4\n",
            "Training xgb1 on dataset 4...\n",
            "Training xgb2 on dataset 4...\n",
            "Training xgb3 on dataset 4...\n",
            "Training rf1 on dataset 4...\n",
            "Training rf2 on dataset 4...\n",
            "Training rf3 on dataset 4...\n",
            "\n",
            "Training models on balanced dataset 5\n",
            "Training xgb1 on dataset 5...\n",
            "Training xgb2 on dataset 5...\n",
            "Training xgb3 on dataset 5...\n",
            "Training rf1 on dataset 5...\n",
            "Training rf2 on dataset 5...\n",
            "Training rf3 on dataset 5...\n",
            "\n",
            "Training models on balanced dataset 6\n",
            "Training xgb1 on dataset 6...\n",
            "Training xgb2 on dataset 6...\n",
            "Training xgb3 on dataset 6...\n",
            "Training rf1 on dataset 6...\n",
            "Training rf2 on dataset 6...\n",
            "Training rf3 on dataset 6...\n",
            "\n",
            "Training meta-model...\n",
            "\n",
            "Preparing test data...\n",
            "\n",
            "Evaluating model on test set...\n",
            "\n",
            "Model Performance Metrics:\n",
            "==================================================\n",
            "Optimal Threshold: 0.0636\n",
            "Accuracy: 0.9334\n",
            "AUC Score: 0.9320\n",
            "Average Precision: 0.4402\n",
            "\n",
            "Confusion Matrix:\n",
            "--------------------------------------------------\n",
            "True Negatives: 750\n",
            "False Positives: 61\n",
            "False Negatives: 0\n",
            "True Positives: 105\n",
            "\n",
            "Additional Metrics:\n",
            "--------------------------------------------------\n",
            "Precision: 0.6325\n",
            "Recall: 1.0000\n",
            "F1 Score: 0.7749\n",
            "\n",
            "Processing validation data...\n",
            "Generating predictions for validation data...\n",
            "Saving validation predictions...\n",
            "\n",
            "Completed! Files saved:\n",
            "1. predictions_balanced_ensemble101.csv - Test set predictions\n",
            "2. validation_predictions.csv - Validation set predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7irVMHoo65yq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}